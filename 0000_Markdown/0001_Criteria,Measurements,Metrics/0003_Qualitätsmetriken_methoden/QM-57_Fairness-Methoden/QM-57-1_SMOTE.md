---
Name: QM-57-1 Synthetic Minority Over-sampling Technique
Title: QM-57-1 Synthetic Minority Over-sampling Technique
TitleGer: QM-57-1 Synthetic Minority Over-sampling Technique
shortdesc: eine Methode zur Erzeugung synthetischer Beispiele der Minderheitsklasse in einem unausgeglichenen Datensatz, um die Klassenverteilung auszugleichen und die Modellleistung zu verbessern.
tags:
  - Qualit√§tsmetrik
ID:
  - QM-57-1
ListMetricID: 
ListMeasureID:
  - "'MA-14'"
  - "'MA-04'"
  - "'MA-30'"
MID: "97"
type:
  - method
lcstep: pre
CodeEx: true
share: true
---
## QM-57-1 Synthetic Minority Over-sampling Technique

### Beschreibung

SMOTE steht f√ºr Synthetic Minority Over-sampling Technique. Es ist eine Methode, die im Bereich des maschinellen Lernens und der Datenanalyse eingesetzt wird, um das Problem unausgeglichener Datens√§tze in Angriff zu nehmen. Unausgeglichene Datens√§tze liegen vor, wenn die Anzahl der Beispiele in den verschiedenen Klassen stark variiert. Dies f√ºhrt oft dazu, dass die Modelle die Mehrheitsklasse(n) bevorzugen und schlecht bei der Vorhersage von Minderheitsklasse(n) abschneiden. SMOTE hilft, dieses Problem zu l√∂sen, indem es k√ºnstliche Datenpunkte f√ºr die Minderheitsklasse generiert, anstatt einfach Kopien der existierenden Minderheitsklassen-Beispiele zu machen (wie es beim herk√∂mmlichen Over-sampling der Fall w√§re). 

Die Technik w√§hlt zuf√§llige Beispiele aus der Minderheitsklasse aus und berechnet dann f√ºr diese Beispiele die k-nearest Neighbor. Synthetische Beispiele werden dann erzeugt, indem f√ºr ein zuf√§llig ausgew√§hltes Beispiel aus der Minderheitsklasse und einen seiner k-n√§chsten Nachbarn ein Vektor zwischen den beiden gezogen und ein neuer Datenpunkt entlang dieses Vektors zuf√§llig platziert wird.

#### Vorteile von SMOTE

- **Verbesserte Klassengleichheit**: Durch die Erh√∂hung der Anzahl von Beispielen in der Minderheitenklasse hilft SMOTE, das Problem des Klassenungleichgewichts zu mildern.
- **Verminderung des Overfittings**: Indem neue, einzigartige Beispiele erzeugt werden, anstatt einfache Kopien zu erstellen, hilft SMOTE, das Overfitting zu reduzieren, das bei traditionellen Oversampling-Techniken auftreten kann.
- **Bessere Generalisierung**: Da die synthetischen Beispiele realistische Variationen zwischen existierenden Beispielen darstellen, kann das Modell besser generalisieren und ist potenziell effektiver bei der Vorhersage neuer, unbekannter Daten.

#### Limitationen von SMOTE

- **Nicht ideal f√ºr hohe Dimensionen**: In sehr hochdimensionalen R√§umen kann SMOTE weniger effektiv sein, da die Distanzberechnung zwischen den Datenpunkten weniger aussagekr√§ftig wird (sog. "Fluch der Dimensionalit√§t").
- **Anf√§lligkeit f√ºr Rauschen**: Wenn die Minderheitenklasse Rauschen enth√§lt, kann SMOTE dieses Rauschen verst√§rken, indem es synthetische Daten erzeugt, die auf rauschbehafteten Beispielen basieren.
- **Nicht geeignet f√ºr kategoriale Daten**: SMOTE ist prim√§r f√ºr kontinuierliche und numerische Daten konzipiert. Bei kategorialen Daten k√∂nnen die interpolierten Werte nicht sinnvoll sein, es sei denn, es werden spezielle Anpassungen vorgenommen.


### Methode

- **Auswahl eines Datensatzes aus der Minderheitenklasse**: Ein zuf√§lliger Datensatz wird aus der Minderheitenklasse ausgew√§hlt.
- **Finden der Nachbarn**: F√ºr den gew√§hlten Datensatz werden die k-n√§chsten Nachbarn in der Minderheitenklasse gefunden. Der Parameter ùëò ist dabei vom Anwender spezifiziert und bestimmt die Anzahl der n√§chsten Nachbarn, die betrachtet werden.
- **Synthetisches Beispiel erzeugen**: Ein Nachbar wird zuf√§llig aus den k-nearest Neighbor ausgew√§hlt. Ein synthetischer Datenpunkt wird dann durch Interpolation zwischen dem urspr√ºnglichen Datenpunkt und diesem zuf√§llig ausgew√§hlten Nachbarn erzeugt. Speziell wird f√ºr jede Feature-Dimension:

![N F ist gleich x i plus Lambda mal in Klammern x n minus x i.](../../../../9999_Images/InterpolierterWert.png)

- NF = Neuer, interpolierter Wert
- $x_i$ = Feature des urspr√ºnglichen Datensatzes
- $lambda$ = Zufallsfaktor, eine Zahl zwischen 0 und 1, die bestimmt wie nahe der neue synthetische Datenpunkt am urspr√ºnglichen Daten im Vergleich zum Nachbarn liegen soll. Ein Wert nahe 0 bedeutet, dass der synthetische Punkt sehr nah am urspr√ºnglichen Datenpunkt liegt, w√§hrend ein Wert nahe 1 bedeutet, dass der synthetische Punkt n√§her am Nachbarn liegt. 
- $x_n$ = Dies ist der Wert desselben Features, aber f√ºr einen der n√§chsten Nachbarn des urspr√ºnglichen Datenpunktes in der Minderheitenklasse


### Pythoncode "SMOTE"
| RefID | Verweis            |
| ----- | ------------------ |
| 78    | QM-57_SMOTE_python |


### Referenzen
| RefID | Verweis                                             | Kurzbeschr.                                                                                                                                                                                                                                                                                                                                                                                         |
| ----- | --------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 186   |  SMOTE: Synthetic Minority Over-sampling Technique  | Das Papier schl√§gt vor, eine √úberstichprobe der Minderheitsklasse mit einer Unterstichprobe der Mehrheitsklasse zu kombinieren, um die Leistung des Klassifikators bei unausgeglichenen Datens√§tzen zu verbessern. Diese Methode √ºbertrifft die alleinige Unterabtastung und Anpassungen in Ripper- und Naive-Bayes-Klassifikatoren, die anhand der konvexen H√ºlle von AUC und ROC bewertet werden. |


